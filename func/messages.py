from aiogram.fsm.context import FSMContext
from config import Form, get_client, get_openai_client, openai_clients, should_bypass_timeout, bot
import tempfile
import os
from datetime import timedelta
from database import load_context,save_context, av_models, trim_context
from aiogram import types
import asyncio
import logging
from aiogram.enums import ParseMode
import time
import aiohttp
import google.generativeai as genai
from keyboards import get_main_keyboard
import re
import multiprocessing
import queue
import base64
import aiofiles
from pydub import AudioSegment

# –°–ø–∏—Å–æ–∫ Markdown-—Å–∏–º–≤–æ–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å
MARKDOWN_SYMBOLS = ['**', '__', '*', '_', '```', '`']

async def split_markdown(text, max_length):
    if len(text) <= max_length:
        return [text]
        
    parts = []
    current_part = ""
    in_code_block = False
    code_block_lang = None
    
    lines = text.splitlines(keepends=True)
    
    for line in lines:
        is_code_block_marker = line.strip().startswith('```')
        
        if is_code_block_marker:
            if not in_code_block:
                lang_match = re.match(r'```(\w+)', line.strip())
                code_block_lang = lang_match.group(1) if lang_match else None
                in_code_block = True
                
                if len(current_part) + len(line) > max_length:
                    parts.append(current_part)
                    current_part = line
                else:
                    current_part += line
            else:
                in_code_block = False
                
                current_part += line
                
                if current_part:
                    parts.append(current_part)
                    current_part = ""
        elif in_code_block:
            if len(current_part) + len(line) > max_length:
                parts.append(current_part)
                current_part = f"```{code_block_lang or ''}\n{line}"
            else:
                current_part += line
        else:
            if len(current_part) + len(line) > max_length:
                if current_part:
                    parts.append(current_part)
                current_part = line
            else:
                current_part += line
                
    if current_part:
        parts.append(current_part)
        
    for i in range(len(parts)):
        open_count = parts[i].count("```") 
        if open_count % 2 != 0: 
            parts[i] += "\n```"
            
    return parts

async def fix_markdown(text):

    open_formats = []
    in_code_block = False
    result = ""
    lines = text.splitlines(keepends=True)

    for line in lines:
        if line.strip().startswith('```'):
            if not in_code_block:
                in_code_block = True
                result += line
            else:
                in_code_block = False
                result += line
        elif in_code_block:
            result += line 
        else:
            
            result += line

    if in_code_block:
        result += '```\n' 

    return result


async def send_message_in_parts(message, response_text, max_length=4050):
    parts = await split_markdown(response_text, max_length)
    for part_index, part in enumerate(parts):
        try:
            fixed_part = await fix_markdown(part) 
            if len(fixed_part) > 4096:

                subparts = []
                current_subpart = ""
                lines = fixed_part.split('\n')
                in_sub_code_block = False

                for line in lines:
                    if line.strip().startswith('```'):
                        if not in_sub_code_block:
                            in_sub_code_block = True
                            if len(current_subpart) + len(line) > 4096 and current_subpart:
                                subparts.append(current_subpart)
                                current_subpart = line + '\n'
                            else:
                                current_subpart += line + '\n'
                        else:
                            in_sub_code_block = False
                            if len(current_subpart) + len(line) > 4096 and current_subpart:
                                subparts.append(current_subpart)
                                subparts.append(line + '\n') 
                                current_subpart = ""
                            else:
                                current_subpart += line + '\n'
                                subparts.append(current_subpart) 
                                current_subpart = ""

                    elif in_sub_code_block:
                        if len(current_subpart) + len(line) > 4096 and current_subpart:
                            subparts.append(current_subpart)
                            current_subpart = line + '\n'
                        else:
                            current_subpart += line + '\n'
                    else:
                        if len(current_subpart) + len(line) > 4096 and current_subpart:
                            subparts.append(current_subpart)
                            current_subpart = line + '\n'
                        else:
                            current_subpart += line + '\n'

                if current_subpart:
                    subparts.append(current_subpart)


                for subpart_index, subpart in enumerate(subparts):
                    if subpart.strip(): 
                        try:
                            await message.answer(subpart, parse_mode=ParseMode.MARKDOWN)
                            await asyncio.sleep(0.1)
                        except Exception as e:
                            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –ø–æ–¥—á–∞—Å—Ç–∏ {subpart_index} —á–∞—Å—Ç–∏ {part_index}: {e}")
                            await message.answer(subpart) 

            else:
                if fixed_part.strip(): 
                    try:
                        await message.answer(fixed_part, parse_mode=ParseMode.MARKDOWN)
                        await asyncio.sleep(0.1)
                    except Exception as e:
                        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —á–∞—Å—Ç–∏ {part_index} —Å Markdown: {e}")
                        await message.answer(part)

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —á–∞—Å—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏—è {part_index}: {e}")
            await message.answer(part) 
            await asyncio.sleep(0.1)


async def convert_dashed_code_blocks_to_markdown(text):
    lines = text.splitlines(keepends=True)
    in_code_block = False
    result = ""
    for line in lines:
        if re.fullmatch(r'---+', line.strip()):
            if not in_code_block:
                result += "```python\n"
                in_code_block = True
            else:
                result += "```\n"
                in_code_block = False
        else:
            result += line
    return result

            
MAX_MESSAGE_LENGTH = 4050

class RateLimiter:
    def __init__(self, rate_limit=5, per_seconds=60):
        self.rate_limit = rate_limit
        self.per_seconds = per_seconds
        self.user_requests = {}
        self.lock = asyncio.Lock()
    
    async def can_process(self, user_id):
        async with self.lock:
            current_time = time.time()
            if user_id not in self.user_requests:
                self.user_requests[user_id] = []
            
            self.user_requests[user_id] = [
                ts for ts in self.user_requests[user_id] 
                if current_time - ts < self.per_seconds
            ]
            
            if len(self.user_requests[user_id]) >= self.rate_limit:
                return False
                
            self.user_requests[user_id].append(current_time)
            return True

async def handle_all_messages(message: types.Message, state: FSMContext, is_admin, is_allowed, audio_response=False):
    user_id = message.from_user.id
    
    current_state = await state.get_state() or Form.waiting_for_message
    
    if not is_admin:
        rate_limiter = RateLimiter(rate_limit=5, per_seconds=60)
        can_process = await rate_limiter.can_process(user_id)
        if not can_process:
            await message.reply("‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ")
            return
    
    start_time = time.time()
    current_time = time.strftime("%H:%M:%S", time.localtime())
   
    user_context = await load_context(user_id)  
    model_key = user_context["model"]  
    model_id, api_type = model_key.split('_')

    user_is_admin = is_admin(user_id)
    user_context["messages"] = await trim_context(user_context["messages"], is_admin=user_is_admin)

    audio_data = None
    audio_file_id = None
    
    if audio_response and (message.voice or message.audio):
        try:
            if message.voice:
                audio_file_id = message.voice.file_id
            else:
                audio_file_id = message.audio.file_id
                
            file = await bot.get_file(audio_file_id)
            file_path = file.file_path
            audio_data = await bot.download_file(file_path)
            
            if hasattr(audio_data, 'read'):
                audio_bytes = audio_data.read()
            else:
                audio_bytes = audio_data
            
            audio_format = "mp3" 
            if message.audio and message.audio.mime_type:
                if "wav" in message.audio.mime_type:
                    audio_format = "wav"
                elif "mp3" in message.audio.mime_type:
                    audio_format = "mp3"
            
            if message.voice:
                audio_format = "ogg"
                
                with tempfile.NamedTemporaryFile(delete=False, suffix='.ogg') as temp_ogg:
                    temp_ogg.write(audio_bytes)
                    temp_ogg_path = temp_ogg.name
                
                temp_mp3_path = temp_ogg_path.replace('.ogg', '.mp3')
                audio = AudioSegment.from_ogg(temp_ogg_path)
                audio.export(temp_mp3_path, format="mp3")
                
                with open(temp_mp3_path, 'rb') as mp3_file:
                    audio_bytes = mp3_file.read()
                
                os.remove(temp_ogg_path)
                os.remove(temp_mp3_path)
                
                audio_format = "mp3"
            
            encoded_audio = base64.b64encode(audio_bytes).decode('utf-8')
                    
            # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è OpenAI —Å –∞—É–¥–∏–æ
            if api_type in list(openai_clients.keys()):
                user_context["messages"].append({
                    "role": "user",
                    "content": [
                        {
                            "type": "input_audio",
                            "input_audio": {
                                "data": encoded_audio,
                                "format": audio_format
                            }
                        }
                    ]
                })
            else:
                await message.reply("üö® –í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ-–æ—Ç–≤–µ—Ç—ã.")
                return
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ: {e}")
            await message.reply(f"üö® –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ: {str(e)}")
            return
    elif message.text:
        if current_state == Form.waiting_for_message:
            if api_type == "gemini":
                last_message = (
                    user_context["messages"][-1]
                    if user_context["messages"]
                    else None
                )
                if last_message and last_message["role"] == "user" and any(
                    "data" in part for part in last_message["parts"]
                ):
                    user_context["messages"][-1]["parts"].append(
                        {"text": message.text}
                    )
                else:
                    user_context["messages"].append(
                        {"role": "user", "parts": [{"text": message.text}]}
                    )
            elif api_type in list(openai_clients.keys()) + ["g4f"]:
                user_context["messages"].append(
                    {"role": "user", "content": message.text}
                )

    allowed_apis = list(openai_clients.keys()) + ["g4f"]

    if (
        current_state == Form.waiting_for_message
        and api_type == "gemini"
    ):
        last_message = (
            user_context["messages"][-1]
            if user_context["messages"]
            else None
        )
        if last_message and last_message["role"] == "user" and any(
            "data" in part for part in last_message["parts"]
        ):
            user_context["messages"][-1]["parts"].append(
                {"text": message.text}
            )
        else:
            user_context["messages"].append(
                {"role": "user", "parts": [{"text": message.text}]}
            )
    elif api_type in allowed_apis:
        
        user_context["messages"].append(
            {"role": "user", "content": message.text}
        )


    response_text = ""
    response_audio = None

    try:
        
        if api_type == "g4f":
            
            if user_context["g4f_image"]:
                def g4f_image_request():
                    user_g4f_client = get_client(user_id, "g4f_image_client", model_name=model_id)
                    return user_g4f_client.chat.completions.create(
                        model=model_id,
                        messages=user_context["messages"],
                        image=user_context["g4f_image"],
                    )

                current_time = time.strftime("%H:%M:%S", time.localtime())
                logging.info(f"[{current_time}] –ù–∞—á–∞–ª–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ G4F image API")

                
                try:
                    response = await async_run_with_timeout(g4f_image_request, 60)
                except TimeoutError as e:
                    logging.error(f"Timeout in g4f_image_request: {e}")
                    await message.reply(f"üïí –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ (60 —Å–µ–∫). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å.")
                    response = None

                if response:
                    response_text = response.choices[0].message.content
                    logging.info(f"–ó–∞–ø—Ä–æ—Å –∫ G4F image API –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {time.time() - start_time:.5f} —Å–µ–∫—É–Ω–¥")
                    user_context["messages"].append(
                        {"role": "assistant", "content": response_text}
                    )
            
            elif user_context["web_search_enabled"]:
                tool_calls = [
                    {
                        "function": {
                            "arguments": {
                                "query": user_context["messages"][-1]["content"],
                                "max_results": 5,
                                "max_words": 2500,
                                "backend": "auto",
                                "add_text": True,
                                "timeout": 5
                            },
                            "name": "search_tool"
                        },
                        "type": "function"
                    }
                ]

                def g4f_web_search_request():
                    user_g4f_client = get_client(user_id, "g4f_client", model_name=model_id)
                    return  user_g4f_client.chat.completions.create(
                        model=model_id,
                        messages=user_context["messages"],
                        tool_calls=tool_calls
                    )

                current_time = time.strftime("%H:%M:%S", time.localtime())
                logging.info(f"[{current_time}] –ù–∞—á–∞–ª–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ G4F —Å –≤–µ–±-–ø–æ–∏—Å–∫–æ–º")

                
                try:
                    response = await async_run_with_timeout(g4f_web_search_request, 60)
                except TimeoutError as e:
                    logging.error(f"Timeout in g4f_web_search_request: {e}")
                    await message.reply(f"üïí –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ (60 —Å–µ–∫). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å.")
                    response = None

                if response:
                    response_text = response.choices[0].message.content
                    logging.info(f"–ó–∞–ø—Ä–æ—Å –∫ G4F —Å –≤–µ–±-–ø–æ–∏—Å–∫–æ–º –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {time.time() - start_time:.5f} —Å–µ–∫—É–Ω–¥")

                    user_context["messages"].append(
                        {"role": "assistant", "content": response_text}
                    )

            else:
                current_time = time.strftime("%H:%M:%S", time.localtime())
                logging.info(f"[{current_time}] –ù–∞—á–∞–ª–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ G4F API")

                def sync_g4f_request():
                    
                    user_g4f_client = get_client(user_id, "g4f_client", model_name=model_id)
                    return user_g4f_client.chat.completions.create(
                        model=model_id,
                        messages=user_context["messages"],
                    )

                if should_bypass_timeout(model_id, api_type):
                    response = await asyncio.to_thread(sync_g4f_request)
                    logging.info(f"–ó–∞–ø—Ä–æ—Å –∫ {api_type} API —Å –º–æ–¥–µ–ª—å—é {model_id} –≤—ã–ø–æ–ª–Ω–µ–Ω –±–µ–∑ —Ç–∞–π–º–∞—É—Ç–∞")
                else:
                    try:
                        response = await async_run_with_timeout(sync_g4f_request, 60)
                    except TimeoutError as e:
                        logging.error(f"Timeout in sync_g4f_request: {e}")
                        await message.reply(f"üïí –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ (60 —Å–µ–∫). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å.")
                        response = None

                if response:
                    response_text = response.choices[0].message.content
                    logging.info(f"–ó–∞–ø—Ä–æ—Å –∫ G4F API –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {time.time() - start_time:.5f} —Å–µ–∫—É–Ω–¥")

                    user_context["messages"].append(
                        {"role": "assistant", "content": response_text}
                    )

        elif api_type == "gemini":
            def gemini_request():
                gemini_model = genai.GenerativeModel(
                    model_id
                )
                
                if not user_context["messages"]:
                    user_context["messages"] = [
                        {"role": "user", "parts": [{"text": message.text}]}
                    ]
                return gemini_model.generate_content(
                    user_context["messages"]
                )       

            current_time = time.strftime("%H:%M:%S", time.localtime())
            logging.info(f"[{current_time}] –ù–∞—á–∞–ª–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ Gemini API")
            
            if should_bypass_timeout(model_id, api_type):
                response = await asyncio.to_thread(gemini_request)
                logging.info(f"–ó–∞–ø—Ä–æ—Å –∫ {api_type} API —Å –º–æ–¥–µ–ª—å—é {model_id} –≤—ã–ø–æ–ª–Ω–µ–Ω –±–µ–∑ —Ç–∞–π–º–∞—É—Ç–∞")
            else:
                try:
                    response = await async_run_with_timeout(gemini_request, 60)
                except TimeoutError as e:
                    logging.error(f"Timeout in gemini_request: {e}")
                    await message.reply(f"üïí –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ (60 —Å–µ–∫). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å.")
                    response = None

            if response:
                response_text = response.text
                logging.info(f"–ó–∞–ø—Ä–æ—Å –∫ Gemini API –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {time.time() - start_time:.5f} —Å–µ–∫—É–Ω–¥")

                user_context["messages"].append(
                    {"role": "model", "parts": [{"text": response_text}]}
                )

        elif api_type in openai_clients:
            if audio_response and model_id == "openai-audio":
                try:
                    client = get_openai_client(api_type)
                    logging.info(f"–ù–∞—á–∞–ª–æ –ø—Ä—è–º–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI Audio API")
                    
                    current_message = []
                    
                    if message.text:
                        current_message = [{"role": "user", "content": message.text}]
                    else:
                        current_message = [
                            {
                                "role": "user",
                                "content": [
                                    {
                                        "type": "input_audio",
                                        "input_audio": {
                                            "data": encoded_audio,
                                            "format": audio_format
                                        }
                                    }
                                ]
                            }
                        ]
                    
                    logging.info("–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –∞—É–¥–∏–æ–º–æ–¥–µ–ª–∏ –±–µ–∑ —É—á–µ—Ç–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
                    
                    result = await asyncio.to_thread(
                        client.chat.completions.create,
                        model=model_id,
                        modalities=["text", "audio"],
                        audio={"voice": "alloy", "format": "wav"},
                        messages=current_message,
                        timeout=90
                    )
                    
                    logging.info(f"–ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –∫ OpenAI Audio API –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                    
                    if result and result.choices:
                        choice = result.choices[0].message
                        if hasattr(choice, 'audio') and choice.audio:
                            response_text = choice.audio.transcript
                            response_audio = base64.b64decode(choice.audio.data)
                            
                            temp_wav_path = f"temp_audio_{user_id}.wav"
                            async with aiofiles.open(temp_wav_path, "wb") as f:
                                await f.write(response_audio)
                            
                            temp_ogg_path = f"temp_audio_{user_id}.ogg"
                            audio = AudioSegment.from_wav(temp_wav_path)
                            audio.export(temp_ogg_path, format="ogg")
                            
                            try:
                                with open(temp_ogg_path, "rb") as audio_file:
                                    await message.answer_audio(
                                        audio=types.BufferedInputFile(audio_file.read(), filename="response.ogg"),
                                        caption=f"üîä –ê—É–¥–∏–æ-–æ—Ç–≤–µ—Ç:\n\n{response_text[:1000]}" if response_text else "üîä –ê—É–¥–∏–æ-–æ—Ç–≤–µ—Ç"
                                    )
                            except Exception as e:
                                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∞—É–¥–∏–æ: {e}")
                                await message.reply("üö® –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∞—É–¥–∏–æ-–æ—Ç–≤–µ—Ç–∞")
                            finally:
                                if os.path.exists(temp_wav_path):
                                    os.remove(temp_wav_path)
                                if os.path.exists(temp_ogg_path):
                                    os.remove(temp_ogg_path)
                            
                            end_time = time.time()
                            processing_time = end_time - start_time
                            formatted_processing_time = str(timedelta(seconds=int(processing_time)))
                            if user_context.get("show_processing_time", True):
                                await message.answer(f"‚è≥ –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {formatted_processing_time}")
                            
                            return
                        else:
                            logging.error("–ú–æ–¥–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –∞—É–¥–∏–æ –≤ –æ—Ç–≤–µ—Ç–µ")
                            await message.reply("üö® –ú–æ–¥–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –∞—É–¥–∏–æ-–æ—Ç–≤–µ—Ç")
                    else:
                        logging.error("–ù–µ –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç API –∏–ª–∏ –æ—Ç–≤–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω")
                        await message.reply("üö® –ù–µ –ø–æ–ª—É—á–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç API")
                        return
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ –∑–∞–ø—Ä–æ—Å–∞: {e}")
                    await message.reply(f"üö® –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ: {str(e)}")
                    return
            elif should_bypass_timeout(model_id, api_type):
                try:
                    result = await asyncio.to_thread(call_openai_completion_sync, api_type, model_id, user_context["messages"])
                    logging.info(f"–ó–∞–ø—Ä–æ—Å –∫ {api_type} API —Å –º–æ–¥–µ–ª—å—é {model_id} –≤—ã–ø–æ–ª–Ω–µ–Ω –±–µ–∑ —Ç–∞–π–º–∞—É—Ç–∞")
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ –∫ {api_type} API: {e}")
                    await message.reply(f"üö® –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
                    result = None
            else:
                try:
                    result = await async_run_with_timeout(call_openai_completion_sync, 60, api_type, model_id, user_context["messages"])
                except TimeoutError as e:
                    logging.error(f"Timeout in openai_client request (long message): {e}")
                    await message.reply("üïí –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ (60 —Å–µ–∫). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å.")
                    result = None

            if result:
                if not hasattr(result, "choices") or not result.choices:
                    logging.error(f"–û—Ç–≤–µ—Ç –æ—Ç {api_type} API –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–∂–∏–¥–∞–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {result}")
                    await message.reply(f"üö® –û—à–∏–±–∫–∞: –ø–æ–ª—É—á–µ–Ω –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç {api_type} API.")
                else:
                    response_text = result.choices[0].message.content
                    user_context["messages"].append({"role": "assistant", "content": response_text})

        if response_text:
            # –£–¥–∞–ª—è–µ–º —Ç–µ–≥–∏ <think> –∏ </think> –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏
            response_text = response_text.replace("<think>", "").replace("</think>", "")
            
            end_time = time.time()
            processing_time = end_time - start_time
            formatted_processing_time = str(timedelta(seconds=int(processing_time)))

            service_info = f"‚è≥ –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {formatted_processing_time}"
            if len(response_text) > MAX_MESSAGE_LENGTH:
                await send_message_in_parts(message, response_text, MAX_MESSAGE_LENGTH)
                with tempfile.NamedTemporaryFile(mode="w+", delete=False, suffix=".txt") as temp_file:
                    temp_file.write(response_text)
                    temp_file_path = temp_file.name

                try:
                    with open(temp_file_path, "rb") as file_to_send:
                        await message.answer_document(types.BufferedInputFile(file_to_send.read(), filename="response.txt"))
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞: {e}")
                    await message.answer("üö® –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç–≤–µ—Ç –≤ –≤–∏–¥–µ —Ñ–∞–π–ª–∞.")
                finally:
                    os.remove(temp_file_path)
            else:
                
                try:
                    await message.answer(response_text, parse_mode=ParseMode.MARKDOWN)
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ Markdown –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
                    try:
                        await message.answer(
                            f"üîî–ü–æ–ø—ã—Ç–∫–∞ —Ñ–∏–∫—Å–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è"
                        )
                        fixed_response = await fix_markdown(response_text)
                        await message.answer(fixed_response,parse_mode=ParseMode.MARKDOWN)
                    except Exception as e:
                        await message.answer(
                            f"üö®–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}\n\n"
                            "–û—Ç–ø—Ä–∞–≤–ª—è—é –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."
                        )
                        await message.answer(response_text)
                        

            await save_context(user_id, user_context)

            if user_context.get("show_processing_time", True):
                await message.answer(service_info)

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞ –∫ API: {e}")
        await message.reply(f"üö®–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
    logging.info(f"–û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {time.time() - start_time:.5f} —Å–µ–∫—É–Ω–¥")



async def cmd_long_message(message: types.Message, state: FSMContext, is_allowed, is_admin):
    user_id = message.from_user.id

    if not is_admin(user_id):
        rate_limiter = RateLimiter(rate_limit=5, per_seconds=60)
        can_process = await rate_limiter.can_process(user_id)
        if not can_process:
            await message.reply("‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ")
            return
        
    start_time = time.time()
    current_time = time.strftime("%H:%M:%S", time.localtime())

    user_context = await load_context(user_id)
    current_state = await state.get_state()

    model_key = user_context["model"]  
    model_id, api_type = model_key.split('_')
    
    user_is_admin = is_admin(user_id)
    user_context["messages"] = await trim_context(user_context["messages"], is_admin=user_is_admin)

    if current_state == Form.waiting_for_long_message:

        if user_context["long_message"]:

            long_message = user_context["long_message"]
            user_context["long_message"] = ""  
            allowed_apis = list(openai_clients.keys()) + ["g4f"]

            if api_type == "gemini":
                last_message = (
                    user_context["messages"][-1]
                    if user_context["messages"]
                    else None
                )
                if last_message and last_message["role"] == "user" and any(
                    "data" in part for part in last_message["parts"]
                ):
                    user_context["messages"][-1]["parts"].append(
                        {"text": long_message}
                    )
                else:
                    user_context["messages"].append(
                        {"role": "user", "parts": [{"text": long_message}]}
                    )
            elif api_type in allowed_apis:
                user_context["messages"].append({"role": "user", "content": long_message})

            response_text = ""

            try:
                if api_type in openai_clients:                    
                    if should_bypass_timeout(model_id, api_type):
                        try:
                            result = await asyncio.to_thread(call_openai_completion_sync, api_type, model_id, user_context["messages"])
                            logging.info(f"–ó–∞–ø—Ä–æ—Å –∫ {api_type} API —Å –º–æ–¥–µ–ª—å—é {model_id} –≤—ã–ø–æ–ª–Ω–µ–Ω –±–µ–∑ —Ç–∞–π–º–∞—É—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ –¥–ª–∏–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è")
                        except Exception as e:
                            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ –∫ {api_type} API –≤ —Ä–µ–∂–∏–º–µ –¥–ª–∏–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
                            await message.reply(f"üö® –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
                            result = None
                    else:
                        try:
                            result = await async_run_with_timeout(call_openai_completion_sync, 60, api_type, model_id, user_context["messages"])
                        except TimeoutError as e:
                            logging.error(f"Timeout in openai_client request (long message): {e}")
                            await message.reply("üïí –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ (60 —Å–µ–∫). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å.")
                            result = None

                    if result:
                        response_text = result.choices[0].message.content

                elif api_type == "g4f":
                    if user_context["g4f_image"] and model_id == user_context["image_recognition_model"]:
                        def g4f_image_request():
                            user_g4f_client = get_client(user_id, "g4f_image_client", model_name=model_id)
                            return user_g4f_client.chat.completions.create(
                                model=model_id,
                                messages=[{"role": "user", "content": long_message}],
                                image=user_context["g4f_image"],
                            )
                        try:
                            response = await async_run_with_timeout(g4f_image_request, 60)
                        except TimeoutError as e:
                            logging.error(f"Timeout in g4f_image_request (long message): {e}")
                            await message.reply(f"üïí –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ (60 —Å–µ–∫). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å.")
                            response = None

                        if response:
                            response_text = response.choices[0].message.content
                    else:
                        def g4f_request():
                            user_g4f_client = get_client(user_id, "g4f_client", model_name=model_id)
                            return user_g4f_client.chat.completions.create(
                                model=model_id,
                                messages=user_context["messages"],
                            )

                        if should_bypass_timeout(model_id, api_type):
                            response = await asyncio.to_thread(g4f_request)
                            logging.info(f"–ó–∞–ø—Ä–æ—Å –∫ {api_type} API —Å –º–æ–¥–µ–ª—å—é {model_id} –≤—ã–ø–æ–ª–Ω–µ–Ω –±–µ–∑ —Ç–∞–π–º–∞—É—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ –¥–ª–∏–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è")
                        else:
                            try:
                                response = await async_run_with_timeout(g4f_request, 60)
                            except TimeoutError as e:
                                logging.error(f"Timeout in g4f_request (long message): {e}")
                                await message.reply(f"üïí –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ (60 —Å–µ–∫). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å.")
                                response = None

                        if response:
                            response_text = response.choices[0].message.content

                elif api_type == "gemini":
                    def gemini_request():
                        gemini_model = genai.GenerativeModel(model_id)
                        return gemini_model.generate_content(user_context["messages"])

                    if should_bypass_timeout(model_id, api_type):
                        response = await asyncio.to_thread(gemini_request)
                        logging.info(f"–ó–∞–ø—Ä–æ—Å –∫ {api_type} API —Å –º–æ–¥–µ–ª—å—é {model_id} –≤—ã–ø–æ–ª–Ω–µ–Ω –±–µ–∑ —Ç–∞–π–º–∞—É—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ –¥–ª–∏–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è")
                    else:
                        try:
                            response = await async_run_with_timeout(gemini_request, 60)
                        except TimeoutError as e:
                            logging.error(f"Timeout in gemini_request (long message): {e}")
                            await message.reply("üïí –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ (60 —Å–µ–∫). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å.")
                            response = None

                    if response:
                        response_text = response.text

                if response_text:
                    # –£–¥–∞–ª—è–µ–º —Ç–µ–≥–∏ <think> –∏ </think> –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏
                    response_text = response_text.replace("<think>", "").replace("</think>", "")
                    
                    end_time = time.time()
                    processing_time = end_time - start_time
                    formatted_processing_time = str(timedelta(seconds=int(processing_time)))

                    service_info = f"‚è≥ –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {formatted_processing_time}"
                    
                    if len(response_text) > MAX_MESSAGE_LENGTH:
                        await send_message_in_parts(message, response_text, MAX_MESSAGE_LENGTH)
                        with tempfile.NamedTemporaryFile(mode="w+", delete=False, suffix=".txt") as temp_file:
                            temp_file.write(response_text)
                            temp_file_path = temp_file.name

                        try:
                            with open(temp_file_path, "rb") as file_to_send:
                                await message.answer_document(types.BufferedInputFile(file_to_send.read(), filename="response.txt"))
                        except Exception as e:
                            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞: {e}")
                            await message.answer("üö® –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç–≤–µ—Ç –≤ –≤–∏–¥–µ —Ñ–∞–π–ª–∞.")
                        finally:
                            os.remove(temp_file_path)
                    else:
                        try:
                            await message.answer(response_text, parse_mode=ParseMode.MARKDOWN)
                        except Exception as e:
                            logging.error(f"–û—à–∏–±–∫–∞ Markdown –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
                            try:
                                await message.answer(
                                    f"üîî–ü–æ–ø—ã—Ç–∫–∞ —Ñ–∏–∫—Å–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è"
                                )
                                fixed_response = await fix_markdown(
                                    response_text
                                )
                                await message.answer(
                                    fixed_response,
                                    parse_mode=ParseMode.MARKDOWN,
                                )
                            except Exception as e:
                                await message.answer(
                                    f"üö®–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}\n\n"
                                    "–û—Ç–ø—Ä–∞–≤–ª—è—é –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."
                                )
                                await message.answer(response_text)
                if api_type != "gemini":
                    user_context["messages"].append(
                        {"role": "assistant", "content": response_text}
                    )
                else:
                    user_context["messages"].append(
                        {"role": "model", "parts": [{"text": response_text}]}
                    )
                await save_context(user_id, user_context)

                if user_context.get("show_processing_time", True):
                    await message.answer(service_info)

            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞ –∫ API: {e}")
                await message.reply(f"üö®–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")

            await message.reply("üîî–î–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ.")
            await state.set_state(Form.waiting_for_message)
        else:
            await state.set_state(Form.waiting_for_message)
            await message.reply("üîî–†–µ–∂–∏–º –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç–∫–ª—é—á–µ–Ω.")
        return

    else:
        await message.reply(
            "üîî–†–µ–∂–∏–º –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω. –û—Ç–ø—Ä–∞–≤—å—Ç–µ /long_message –µ—â–µ —Ä–∞–∑, —á—Ç–æ–±—ã –∑–∞–≤–µ—Ä—à–∏—Ç—å –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ –∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏."
        )
        await state.set_state(Form.waiting_for_long_message)
        
async def handle_long_message(message: types.Message, state: FSMContext):
    user_id = message.from_user.id
    user_context = await load_context(user_id)

    user_context["long_message"] += message.text + "\n"
    await save_context(user_id, user_context)
    await message.reply("üîî–°–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –∫ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—é.")



def call_openai_completion_sync(api_type, model, messages, **kwargs):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –≤—ã–∑–æ–≤–∞ OpenAI API, –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ async_run_with_timeout."""
    client = get_openai_client(api_type)
    start_time = time.time()
    start_timestamp = time.strftime("%H:%M:%S", time.localtime(start_time))
    logging.info(f"[{start_timestamp}] –ù–∞—á–∞–ª–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI API ({api_type}) —Å –º–æ–¥–µ–ª—å—é {model}.")
    try:
        result =  client.chat.completions.create(model=model, messages=messages, **kwargs)
        end_time = time.time()
        duration = end_time - start_time
        end_timestamp = time.strftime("%H:%M:%S", time.localtime(end_time))
        logging.info(f"[{end_timestamp}] –ó–∞–ø—Ä–æ—Å –∫ OpenAI API ({api_type}) –∑–∞–≤–µ—Ä—à—ë–Ω –∑–∞ {duration:.2f} —Å–µ–∫—É–Ω–¥.")
        return result
    except Exception as e:
        end_time = time.time()
        duration = end_time - start_time
        end_timestamp = time.strftime("%H:%M:%S", time.localtime(end_time))
        logging.error(f"[{end_timestamp}] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI API ({api_type}) —Å –º–æ–¥–µ–ª—å—é {model} –ø–æ—Å–ª–µ {duration:.2f} —Å–µ–∫—É–Ω–¥: {e}")
        raise



def run_in_process(func, timeout, *args, **kwargs):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –±–ª–æ–∫–∏—Ä—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é func –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ —Å —Ç–∞–π–º–∞—É—Ç–æ–º.
    –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å –∑–∞ timeout —Å–µ–∫—É–Ω–¥, –ø—Ä–æ—Ü–µ—Å—Å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è.
    –†–µ–∑—É–ª—å—Ç–∞—Ç (–∏–ª–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ) –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ –æ—á–µ—Ä–µ–¥—å."""
    result_queue = multiprocessing.Queue()

    def wrapper():
        try:
            result = func(*args, **kwargs)
            result_queue.put((True, result))
        except Exception as ex:
            result_queue.put((False, ex))

    process = multiprocessing.Process(target=wrapper)
    process.start()
    process.join(timeout)
    if process.is_alive():
        process.terminate()
        process.join(1)
        raise TimeoutError(f"–í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–µ–≤—ã—Å–∏–ª —Ç–∞–π–º–∞—É—Ç {timeout} —Å–µ–∫.")
    try:
        success, result = result_queue.get_nowait()
        if success:
            return result
        else:
            raise result
    except queue.Empty:
        raise Exception("–û—à–∏–±–∫–∞: —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç.")

async def async_run_with_timeout(func, timeout, *args, **kwargs):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±–ª–æ–∫–∏—Ä—É—é—â–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π —Å —Ç–∞–π–º–∞—É—Ç–æ–º —á–µ—Ä–µ–∑ –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å."""
    loop = asyncio.get_running_loop()
    return await loop.run_in_executor(None, run_in_process, func, timeout, *args, **kwargs)
