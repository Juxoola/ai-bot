from config import bot, g4f_client, get_client,Form, openai_clients
import config
from key import GEMINI_API_KEY
from aiogram.fsm.context import FSMContext
from database import load_context,save_context,def_enhance, def_gen_model, def_aspect
from aiogram import types
import asyncio
import logging
from io import BytesIO
import tempfile
import os
from func.openai_image import run_with_timeout
import aiohttp
from urllib.parse import quote
import random
from google import genai
from google.genai import types as genai_types
from datetime import timedelta
import time
from PIL import Image

new_api_models = ["flux", "turbo"]
fresed_models = ["stable-diffusion-3", "stable-diffusion-3-large", "stable-diffusion-3-large-turbo", "flux-pro-1.1", "flux-pro-1"]
google_ai_models = ["gemini-2.0-flash-exp"]

if GEMINI_API_KEY:
    genai_client = genai.Client(api_key=GEMINI_API_KEY)
else:
    genai_client = None
    logging.warning("GEMINI_API_KEY is not set. Google AI image generation will be unavailable.")

async def process_image_generation_prompt(message: types.Message, state: FSMContext):
    start_time = time.time()

    data = await state.get_data()
    prompt = data.get("image_generation_prompt")
    is_direct_image_gen = data.get("is_direct_image_gen", False)

    if not is_direct_image_gen:
        await message.reply(
            f"üîî–¢–≤–æ–π –∑–∞–ø—Ä–æ—Å '{message.text}' –±—ã–ª –ø–µ—Ä–µ–≤–µ–¥–µ–Ω –∫–∞–∫ '{prompt}'.\n–ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é..."
        )

    await state.update_data(image_generation_prompt=prompt)

    user_id = message.from_user.id
    user_context = await load_context(user_id)
    DEFAULT_IMAGE_GEN_MODEL = await def_gen_model()
    DEFAULT_ASPECT_RATIO = await def_aspect()
    DEFAULT_ENHANCE = await def_enhance()
    
    model_info = user_context.get("image_generation_model", DEFAULT_IMAGE_GEN_MODEL)
    
    if isinstance(model_info, dict):
        model_id = model_info.get("model_id")
        api_type = model_info.get("api")
    else:
  
        last_underscore_pos = model_info.rfind('_')
        if last_underscore_pos != -1:
            model_id = model_info[:last_underscore_pos]
            api_type = model_info[last_underscore_pos+1:]
        else:
            model_id = model_info
            api_type = "poli"  # API –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    aspect_ratio = user_context.get("aspect_ratio", DEFAULT_ASPECT_RATIO)
    enhance = user_context.get("enhance", DEFAULT_ENHANCE)
    
    await state.update_data(image_generation_model=model_id)
    await state.update_data(image_generation_model_api=api_type)
    await state.update_data(aspect_ratio=aspect_ratio)
    await state.update_data(enhance=enhance)

    aspect_ratio_options = {
        "1:1": (2048, 2048),
        "3:2": (1536, 1024),
        "2:3": (1024, 1536),
        "4:3": (1536, 1152),
        "3:4": (1152, 1536),
        "16:9": (1792, 1024),
        "9:16": (1024, 1792),
        "21:9": (2048, 896),
    }
    width, height = aspect_ratio_options.get(aspect_ratio, (1024, 1024)) 


    # –£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π, –µ—Å–ª–∏ enhance=True
    if enhance:
        try:
            system_prompt = "YOU ARE AN ELITE PROMPT ENGINEER SPECIALIZING IN ENHANCING PROMPTS FOR IMAGE DESCRIPTION GENERATION. YOUR TASK IS TO ACCEPT A TEXT INPUT IN ANY LANGUAGE AND PRODUCE AN OPTIMIZED PROMPT IN ENGLISH FOR A GENERATIVE MODEL. THE OPTIMIZED PROMPT MUST INCLUDE A DETAILED DESCRIPTION OF THE SCENE, SPECIFYING WHAT IS HAPPENING AND INCORPORATING SUBTLE DETAILS TO ENSURE BEAUTIFUL VISUALIZATION. YOUR OUTPUT SHOULD BE THE DESCRIPTION IN ENGLISH ONLY, WITHOUT ANY ADDITIONAL COMMENTS OR EXPLANATIONS. ###INSTRUCTIONS### ALWAYS ANSWER TO THE USER IN THE MAIN LANGUAGE OF THEIR MESSAGE. 1. **TRANSLATE** the provided input text to English if necessary. 2. **ANALYZE** the scene to identify all critical elements such as the setting, actions, characters, and objects. 3. **ENRICH** the description by adding subtle details that enhance the visual quality and realism of the scene. 4. **ENSURE** the prompt is clear. vivid. and evocative to aid the generative model in"
            improved_prompt = await asyncio.to_thread(
                lambda:
                    config.enhance_prompt_client.chat.completions.create(
                        model="llama-3.3-70b",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": prompt}
                        ],
                    )
            )
            prompt = improved_prompt.choices[0].message.content
        except Exception as e:
            logging.error(f"Error during prompt improvement: {e}")
            await bot.send_message(user_id, f"üö®–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏ –ø—Ä–æ–º–ø—Ç–∞: {e}")

    if api_type == "poli":
        async def fetch_image():
            encoded_prompt = quote(prompt)
            url = f"https://image.pollinations.ai/prompt/{encoded_prompt}"
            api_model_name = model_id 
            params = {
                "width": width,
                "height": height,
                "enhance": "false", 
                "model": api_model_name,
                "seed": random.randint(0, 1000000),
                "nologo": "true",
                "private": "true",
                "safe": "false"
            }
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(url, params=params) as response:
                        if response.status == 200:
                            image_data = await response.read()
                            return image_data
                        else:
                            error_message = await response.text()
                            return response.status, error_message 
            except Exception as e:
                logging.error(f"Error during image generation: {e}")
                raise e
        retry_count = 0
        max_retries = 3
        while retry_count < max_retries:
            try:
                result = await asyncio.to_thread(lambda: asyncio.run(fetch_image()))
                if isinstance(result, tuple) and result[0] == 500: 
                    status_code, error_message = result
                    retry_count += 1
                    await bot.send_message(
                        user_id, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ 500 –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–ø—ã—Ç–∫–∞ {retry_count}/{max_retries}..."
                    )
                    if retry_count == max_retries:
                        await bot.send_message(
                            user_id, f"üö® –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫. –û—à–∏–±–∫–∞: {error_message}"
                        )
                        break 
                    await asyncio.sleep(1) 
                else:
                    image_data = result
                    caption = f"–§–æ—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –º–æ–¥–µ–ª—å—é {model_id}"
                    if aspect_ratio:
                        caption += f" —Å —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ–º —Å—Ç–æ—Ä–æ–Ω {aspect_ratio}"
                    if enhance:
                        caption += f", enhance: {enhance}"
                    caption += ":"
                    await bot.send_photo(
                        user_id,
                        photo=types.BufferedInputFile(image_data, filename="image.jpg"),
                        caption=caption,
                    )
                    caption2 = "–§–æ—Ç–æ –±–µ–∑ —Å–∂–∞—Ç–∏—è"
                    await bot.send_document(user_id, document=types.BufferedInputFile(image_data, filename="image.jpg"), caption=caption2)
                    break
            except Exception as e:
                await bot.send_message(
                    user_id, f"üö®–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}"
                )
                break 

    elif api_type in openai_clients and api_type != "poli":
        client = openai_clients.get(api_type)
        try:
            size_str = f"{width}x{height}"
            response = await run_with_timeout(
                client.images.generate(
                    model=model_id,
                    prompt=prompt,
                    size=size_str
                ),
                timeout=60,
                msg=message
            )
            if response is None:
                return
            if hasattr(response, 'generated_images'):
                image_data = response.generated_images[0].image.getvalue()
            elif hasattr(response, 'data') and response.data:
                image_url = response.data[0].url
                async with aiohttp.ClientSession() as session:
                    async with session.get(image_url) as resp:
                        if resp.status == 200:
                            image_data = await resp.read()
                        else:
                            raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, —Å—Ç–∞—Ç—É—Å: {resp.status}")
            else:
                raise Exception(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç {api_type} client")
            caption = f"–§–æ—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {api_type} –º–æ–¥–µ–ª—å—é {model_id}"
            if aspect_ratio:
                caption += f" —Å —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ–º —Å—Ç–æ—Ä–æ–Ω {aspect_ratio}"
            if enhance:
                caption += f", enhance: {enhance}"
            caption += ":"
            await bot.send_photo(
                user_id,
                photo=types.BufferedInputFile(image_data, filename="image.jpg"),
                caption=caption,
            )
            caption2 = "–§–æ—Ç–æ –±–µ–∑ —Å–∂–∞—Ç–∏—è"
            await bot.send_document(
                user_id,
                document=types.BufferedInputFile(image_data, filename="image.jpg"),
                caption=caption2,
            )
        except Exception as e:
            logging.error(f"Error during {api_type} image generation: {e}")
            await bot.send_message(user_id, f"üö®–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é {api_type} client: {e}")

    elif api_type == "gemini":
        if genai_client:
            try:
                response_coroutine = asyncio.to_thread(
                    lambda: genai_client.models.generate_content(
                        model=model_id,
                        contents=prompt,
                        config=genai_types.GenerateContentConfig(
                            response_modalities=['Text', 'Image']
                        )
                    )
                )
                
                response = await run_with_timeout(
                    response_coroutine,
                    timeout=60,
                    msg=message
                )
                
                if response is None:
                    return
                
                image_data = None
                text_response = ""
                
                if hasattr(response, 'candidates') and response.candidates and hasattr(response.candidates[0], 'content'):
                    for part in response.candidates[0].content.parts:
                        if part.text:
                            text_response += part.text
                        
                        if part.inline_data is not None and part.inline_data.mime_type.startswith('image/'):
                            image_data = part.inline_data.data
                
                if not image_data:
                    error_message = "üö®–ú–æ–¥–µ–ª—å –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –æ—Ç–≤–µ—Ç–µ."
                    if text_response:
                        error_message += f"\n\n–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {text_response}"
                    await bot.send_message(user_id, error_message)
                    return

                caption = f"–§–æ—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –º–æ–¥–µ–ª—å—é {model_id}"
                if enhance:
                    caption += f", enhance: {enhance}"
                caption += ":"
                
                await bot.send_photo(
                    user_id,
                    photo=types.BufferedInputFile(image_data, filename="image.jpg"),
                    caption=caption,
                )
                
                caption2 = "–§–æ—Ç–æ –±–µ–∑ —Å–∂–∞—Ç–∏—è"
                await bot.send_document(
                    user_id, 
                    document=types.BufferedInputFile(image_data, filename="image.jpg"),
                    caption=caption2,
                )
            except Exception as e:
                logging.error(f"Error during Gemini image generation: {e}")
                await bot.send_message(user_id, f"üö®–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é Gemini API: {e}")
        else:
            await bot.send_message(user_id, "üö®–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. API-–∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.")

    elif api_type == "g4f":
        image_gen_client = get_client(user_id, "g4f_image_gen_client", model_name=model_id)
    
        try:
            response_coroutine = asyncio.to_thread(
                lambda: image_gen_client.images.generate(
                    prompt=prompt,
                    model=model_id,
                    response_format="url",
                    enhance=False,
                    private=True,
                    width=width,
                    height=height,
                )
            )
            response = await run_with_timeout(response_coroutine, timeout=60, msg=message)
    
            if response is None:
                return
            
            image_url = response.data[0].url
            caption = f"–§–æ—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –º–æ–¥–µ–ª—å—é {model_id}"
            if aspect_ratio:
                caption += f" —Å —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ–º —Å—Ç–æ—Ä–æ–Ω {aspect_ratio}"
            if enhance:
                caption += f", enhance: {enhance}"
            caption += ":"
            await bot.send_photo(
                user_id,
                photo=image_url,
                caption=caption,
            )
            caption2 = "–§–æ—Ç–æ –±–µ–∑ —Å–∂–∞—Ç–∏—è"
            await bot.send_document(user_id, document=image_url, caption=caption2)
        except Exception as e:
            logging.error(f"Error during image generation: {e}")
            await bot.send_message(user_id, f"üö®–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")

    end_time = time.time()
    processing_time = end_time - start_time
    formatted_processing_time = str(timedelta(seconds=int(processing_time)))
    service_info = f"‚è≥ –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {formatted_processing_time}"

    if user_context.get("show_processing_time", True):
        await bot.send_message(user_id, service_info)

    await state.set_state(Form.waiting_for_message)
    await state.update_data(image_generation_prompt=None)
    await state.update_data(aspect_ratio=None)
    await state.update_data(enhance=None)


async def handle_image_recognition(message: types.Message, state: FSMContext):
    user_id = message.from_user.id

    photo = message.photo[-1]
    file_id = photo.file_id
    file = await bot.get_file(file_id)
    file_path = file.file_path
    image_data = await bot.download_file(file_path)
    image = BytesIO(image_data.read())
    image.seek(0)

    user_context = await load_context(user_id)
    user_context["g4f_image"] = image
    await save_context(user_id, user_context)

    await bot.send_message(user_id, "üîî–í–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:")


async def handle_files_or_urls(message: types.Message, state: FSMContext):
    user_id = message.from_user.id
    
    try:
        if message.document:
            processing_msg = await message.reply("üîî –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞...")

            file_id = message.document.file_id
            file = await bot.get_file(file_id)
            file_path = file.file_path
            file_data = await bot.download_file(file_path)

            with tempfile.NamedTemporaryFile(
                delete=False, suffix=f"_{message.document.file_name}"
            ) as tmp_file:
                tmp_file.write(file_data.read())
                temp_file_path = tmp_file.name

            file_content = await asyncio.to_thread(process_local_file, temp_file_path)

            if file_content == "Unsupported file type":
                await processing_msg.edit_text(
                    "üö® –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:\n"
                    "- –î–æ–∫—É–º–µ–Ω—Ç—ã: PDF, DOCX, DOC, XLSX, XLS\n"
                    "- –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã: TXT, CSV, MD\n"
                    "- –ö–æ–¥: PY, JS, PHP, HTML, XML, JSON, YAML, SQL –∏ –¥—Ä—É–≥–∏–µ"
                )
                return
            elif file_content == "Error processing file":
                await processing_msg.edit_text(
                    "üö® –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
                )
                return

            user_context = await load_context(user_id)
            model_key = user_context["model"]  
            model_id, api_type = model_key.split('_')
            allowed_apis = list(openai_clients.keys()) + ["g4f"]

            if api_type == "gemini":
                last_message = user_context["messages"][-1] if user_context["messages"] else None
                if last_message and last_message["role"] == "user" and any("data" in part for part in last_message["parts"]):
                    user_context["messages"][-1]["parts"].append({"text": file_content})
                else:
                    user_context["messages"].append({"role": "user", "parts": [{"text": file_content}]})
            elif api_type in  allowed_apis:
                user_context["messages"].append({"role": "user", "content": file_content})

            await save_context(user_id, user_context)

            await processing_msg.edit_text("üîî –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ –¥–æ–±–∞–≤–ª–µ–Ω –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç.")
            await state.set_state(Form.waiting_for_message)

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")
        if 'processing_msg' in locals():
            await processing_msg.edit_text(f"üö® –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")
        else:
            await message.reply(f"üö® –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")
        await state.set_state(Form.waiting_for_message)
    finally:
        if "temp_file_path" in locals() and os.path.exists(temp_file_path):
            os.remove(temp_file_path)

def process_local_file(file_path):
    import fitz 
    import os
    import logging
    
    file_content = ""
    try:
        file_ext = os.path.splitext(file_path)[1].lower()
        
        # PDF —Ñ–∞–π–ª—ã
        if file_ext == ".pdf":
            with fitz.open(file_path) as doc:
                for page in doc:
                    file_content += page.get_text()
        
        # Microsoft Word (.docx) –¥–æ–∫—É–º–µ–Ω—Ç—ã
        elif file_ext == ".docx":
            from docx import Document
            doc = Document(file_path)
            for para in doc.paragraphs:
                file_content += para.text + "\n"
            # –¢–∞–∫–∂–µ –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ç–∞–±–ª–∏—Ü
            for table in doc.tables:
                for row in table.rows:
                    row_text = []
                    for cell in row.cells:
                        row_text.append(cell.text)
                    file_content += " | ".join(row_text) + "\n"
        
        # –°—Ç–∞—Ä—ã–µ Microsoft Word (.doc) –¥–æ–∫—É–º–µ–Ω—Ç—ã
        elif file_ext == ".doc":
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º antiword –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π —Å–ø–æ—Å–æ–±
                import subprocess
                result = subprocess.run(['antiword', file_path], capture_output=True, text=True)
                if result.returncode == 0:
                    file_content = result.stdout
                else:
                    raise Exception(f"antiword –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {result.stderr}")
            except Exception as e2:
                logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å .doc —Å –ø–æ–º–æ—â—å—é antiword: {e2}")
                try:
                    # –ü—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ libreoffice –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
                    import os
                    tmp_txt = f"{file_path}.txt"
                    result = subprocess.run(['libreoffice', '--headless', '--convert-to', 'txt', file_path, 
                                             '--outdir', os.path.dirname(file_path)], 
                                            capture_output=True, text=True)
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                    base_name = os.path.basename(file_path)
                    file_name_without_ext = os.path.splitext(base_name)[0]
                    converted_txt = os.path.join(os.path.dirname(file_path), f"{file_name_without_ext}.txt")
                    
                    if os.path.exists(converted_txt):
                        with open(converted_txt, 'r', encoding='utf-8', errors='ignore') as f:
                            file_content = f.read()
                        os.remove(converted_txt)
                    else:
                        raise Exception("–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")
                except Exception as e3:
                    logging.error(f"–í—Å–µ –º–µ—Ç–æ–¥—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ .doc –Ω–µ —É–¥–∞–ª–∏—Å—å: {e3}")
                    return "Error processing .doc file: All methods failed"
        
        # Microsoft Excel (.xlsx) —Ç–∞–±–ª–∏—Ü—ã
        elif file_ext == ".xlsx":
            import openpyxl
            wb = openpyxl.load_workbook(file_path, data_only=True)
            for sheet in wb.worksheets:
                file_content += f"–õ–∏—Å—Ç: {sheet.title}\n"
                for row in sheet.iter_rows(values_only=True):
                    file_content += " | ".join([str(cell) if cell is not None else "" for cell in row]) + "\n"
                file_content += "\n"
        
        # –°—Ç–∞—Ä—ã–µ Microsoft Excel (.xls) —Ç–∞–±–ª–∏—Ü—ã
        elif file_ext == ".xls":
            try:
                import xlrd
                wb = xlrd.open_workbook(file_path)
                for sheet_index in range(wb.nsheets):
                    sheet = wb.sheet_by_index(sheet_index)
                    file_content += f"–õ–∏—Å—Ç: {sheet.name}\n"
                    for row_index in range(sheet.nrows):
                        row_values = sheet.row_values(row_index)
                        file_content += " | ".join([str(cell) if cell else "" for cell in row_values]) + "\n"
                    file_content += "\n"
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ .xls —Ñ–∞–π–ª–∞: {e}")
                try:
                    # –†–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥ —á–µ—Ä–µ–∑ libreoffice
                    tmp_csv = f"{file_path}.csv"
                    result = subprocess.run(['libreoffice', '--headless', '--convert-to', 'csv', file_path, 
                                             '--outdir', os.path.dirname(file_path)], 
                                            capture_output=True, text=True)
                    if os.path.exists(tmp_csv):
                        with open(tmp_csv, 'r', encoding='utf-8', errors='ignore') as f:
                            file_content = f.read()
                        os.remove(tmp_csv)
                    else:
                        raise Exception("–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")
                except Exception as e2:
                    logging.error(f"–í—Å–µ –º–µ—Ç–æ–¥—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ .xls –Ω–µ —É–¥–∞–ª–∏—Å—å: {e2}")
                    return "Error processing .xls file: All methods failed"
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
        elif file_ext in (
            ".txt", ".xml", ".json", ".js", ".har", ".sh", ".py",
            ".php", ".css", ".yaml", ".sql", ".log", ".csv", ".twig", ".md",
            ".c", ".cpp", ".h", ".java", ".rb", ".pl", ".rs", ".go", ".ts", ".jsx", ".tsx",
            ".conf", ".ini", ".toml", ".lua", ".bat", ".ps1", ".yml"
        ):
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                file_content += f.read()
        else:
            return "Unsupported file type"
            
        return file_content
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")
        return f"Error processing file: {str(e)}"

async def process_image_editing(message: types.Message, state: FSMContext):
    start_time = time.time()
    user_id = message.from_user.id
    
    data = await state.get_data()
    image_data = data.get("image_edit_data")
    instructions = data.get("image_edit_instructions")
    
    if not image_data or not instructions:
        await message.reply("üö® –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—é")
        await state.set_state(Form.waiting_for_message)
        return
    
    user_context = await load_context(user_id)
    model_info = user_context.get("image_generation_model")
    
    if isinstance(model_info, dict):
        model_id = model_info.get("model_id")
        api_type = model_info.get("api")
    else:
        last_underscore_pos = model_info.rfind('_')
        if last_underscore_pos != -1:
            model_id = model_info[:last_underscore_pos]
            api_type = model_info[last_underscore_pos+1:]
        else:
            model_id = model_info
            api_type = "poli" 
    
    if api_type == "gemini" and model_id in google_ai_models:
        try:
            if isinstance(image_data, list):
                pil_images = []
                for img in image_data:
                    if hasattr(img, 'read'):
                        image_bytes = BytesIO(img.read())
                    else:
                        image_bytes = BytesIO(img)
                    image_bytes.seek(0)
                    pil_img = await asyncio.to_thread(lambda: Image.open(image_bytes))
                    pil_images.append(pil_img)
            else:
                image_bytes = BytesIO(image_data.read())
                image_bytes.seek(0)
                pil_img = await asyncio.to_thread(lambda: Image.open(image_bytes))
                pil_images = [pil_img]
    
            contents = [instructions, *pil_images]
    
            response_coroutine = asyncio.to_thread(
                lambda: genai_client.models.generate_content(
                    model=model_id,
                    contents=contents,
                    config=genai_types.GenerateContentConfig(
                        response_modalities=['Text', 'Image']
                    )
                )
            )
            
            response = await run_with_timeout(
                response_coroutine,
                timeout=60, 
                msg=message
            )
            
            if response is None:
                await bot.send_message(
                    user_id, 
                    "üö® –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –ø—Ä–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
                )
                await state.set_state(Form.waiting_for_message)
                return
            
            edited_image_data = None
            text_response = ""
            
            if hasattr(response, 'candidates') and response.candidates and hasattr(response.candidates[0], 'content'):
                for part in response.candidates[0].content.parts:
                    if hasattr(part, 'text') and part.text:
                        text_response += part.text
                    
                    if hasattr(part, 'inline_data') and part.inline_data and part.inline_data.mime_type.startswith('image/'):
                        edited_image_data = part.inline_data.data
            
            if not edited_image_data:
                error_message = "üö® –ú–æ–¥–µ–ª—å –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∞ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –æ—Ç–≤–µ—Ç–µ."
                if text_response:
                    error_message += "\n\n–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: " + text_response[:3000]
                await bot.send_message(user_id, error_message)
                await state.set_state(Form.waiting_for_message)
                return
            
            caption = f"‚úèÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–æ —Å –ø–æ–º–æ—â—å—é {model_id}"
            await bot.send_photo(
                user_id,
                photo=types.BufferedInputFile(edited_image_data, filename="edited_image.jpg"),
                caption=caption,
            )
            
            if text_response:
                await bot.send_message(user_id, text_response)
            
            await bot.send_document(
                user_id, 
                document=types.BufferedInputFile(edited_image_data, filename="edited_image.jpg"), 
                caption="–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–µ–∑ —Å–∂–∞—Ç–∏—è"
            )
            
        except Exception as e:
            logging.error(f"Error during image editing: {e}")
            error_message = f"üö® –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)[:200]}"
            await bot.send_message(user_id, error_message)
    else:
        await bot.send_message(
            user_id, 
            "üö® –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª—è–º–∏ Google AI. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏–∑–º–µ–Ω–∏—Ç–µ –º–æ–¥–µ–ª—å –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö."
        )
    
    end_time = time.time()
    processing_time = end_time - start_time
    formatted_processing_time = str(timedelta(seconds=int(processing_time)))
    
    if user_context.get("show_processing_time", True):
        await bot.send_message(user_id, f"‚è≥ –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {formatted_processing_time}")
    
    await state.set_state(Form.waiting_for_message)
    await state.update_data(image_edit_data=None)
    await state.update_data(image_edit_instructions=None)
