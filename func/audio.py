from config import bot,Form,groq_client
from aiogram.fsm.context import FSMContext
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton
from aiogram import types
import asyncio
import logging
import tempfile
import os

async def handle_audio(message: types.Message, state: FSMContext,WHISPER_MODELS):

    if message.audio:
        file_size = message.audio.file_size
        file_id = message.audio.file_id
    elif message.voice:
        file_size = message.voice.file_size
        file_id = message.voice.file_id
    elif message.document and message.document.mime_type.startswith('audio/'):
        file_size = message.document.file_size
        file_id = message.document.file_id
    elif message.video_note:
        file_size = message.video_note.file_size
        file_id = message.video_note.file_id
    else:
        await message.reply("üîî–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ, –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –≤–∏–¥–µ–æ—Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –∞—É–¥–∏–æ-–¥–æ–∫—É–º–µ–Ω—Ç.")
        return

    max_telegram_file_size = 20 * 1024 * 1024  # 20 MB limit for Telegram
    if file_size > max_telegram_file_size:
        await message.reply("üîî–ê—É–¥–∏–æ—Ñ–∞–π–ª –∏–ª–∏ –≤–∏–¥–µ–æ—Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª –º–µ–Ω—å—à–µ 20 –ú–ë.")
        return

    try:
        file = await bot.get_file(file_id)
        file_path = file.file_path
        audio_data = await bot.download_file(file_path)

        with tempfile.NamedTemporaryFile(delete=False, suffix=".m4a") as tmp_file:
            tmp_file.write(audio_data.read())
            temp_audio_path = tmp_file.name

        keyboard = InlineKeyboardMarkup(inline_keyboard=[])
        keyboard.inline_keyboard.append([InlineKeyboardButton(text=f"----- –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å Whisper -----", callback_data="ignore")])

        buttons_row = []
        for model_name in WHISPER_MODELS:
            button = InlineKeyboardButton(text=model_name, callback_data=f"whisper_model_{model_name}")
            buttons_row.append(button)
            if len(buttons_row) == 2:
                keyboard.inline_keyboard.append(buttons_row)
                buttons_row = []

        if buttons_row:
            keyboard.inline_keyboard.append(buttons_row)

        msg = await message.reply("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ:", reply_markup=keyboard)
        await state.update_data(model_selection_message_id=msg.message_id, temp_audio_path=temp_audio_path)
        await state.set_state(Form.waiting_for_whisper_model_selection)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ –∏–∑ Telegram: {e}")
        await message.reply("üö®–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –∏–∑ Telegram. –í–æ–∑–º–æ–∂–Ω–æ, —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π.")



async def process_whisper_model_selection(callback_query: types.CallbackQuery, state: FSMContext):
    user_id = callback_query.from_user.id
    model_name = callback_query.data.split("_", 2)[2]

    data = await state.get_data()
    model_selection_message_id = data.get("model_selection_message_id")
    temp_audio_path = data.get("temp_audio_path")

    if model_selection_message_id:
        try:
            await bot.delete_message(chat_id=callback_query.message.chat.id, message_id=model_selection_message_id)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏: {e}")

    try:
        file_size = os.path.getsize(temp_audio_path)
        max_file_size = 25 * 1024 * 1024  # 25 MB limit

        if file_size > max_file_size:
            await bot.send_message(user_id, "üîî–ê—É–¥–∏–æ—Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª –º–µ–Ω—å—à–µ 25 –ú–ë.")
            return

        transcription_text = await asyncio.to_thread(
            lambda: transcribe_audio_sync(groq_client, temp_audio_path, model_name)
        )

        if transcription_text:
            await bot.send_message(user_id, transcription_text)
        else:
            await bot.send_message(user_id, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é.")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
        await bot.send_message(user_id, f"üö®–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
    finally:
        if temp_audio_path and os.path.exists(temp_audio_path):
            os.remove(temp_audio_path)
    await state.set_state(Form.waiting_for_message)


def transcribe_audio_sync(groq_client, temp_audio_path, model_name):
    try:
        with open(temp_audio_path, "rb") as audio_file:
            transcription = groq_client.audio.transcriptions.create(
                file=audio_file,
                model=model_name,
                response_format="verbose_json",
            )
            return transcription.text
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
        return None
